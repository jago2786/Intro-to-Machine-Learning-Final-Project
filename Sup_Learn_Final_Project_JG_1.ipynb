{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bfbf2da-1e88-42ae-bc35-dc15b9435be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb958f55-40a0-4832-9cd8-e60b0113b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Dataset, which is 500 generated 32x32 images with a background of 0s, each with a 3x3 square of 1s placed randomly in the image.\n",
    "#These images are a substitute for clinical MRI data that can't be shared for privacy reasons\n",
    "#Images were scored by summing the value of all pixels in each quadrent, then assigning a score based on the max quadrent value\n",
    "#This scoring format from 0-3 was intended to be similar to the 0-4 integer image quality scores on the clinical MRI data \n",
    "#Pixel values were converted into single excel row of 1024 columns (excel column = image column value + 32 * image row value), and score was placed in 1025th column\n",
    "df = pd.read_excel(\"path_to_dataset\") #Replace with path\n",
    "#Since the data was self-generated, there was no need to clean it. \n",
    "#If it were the clinical data failed scans (wrong timing, corrupted data, and mis-labeled scans, etc) would be removed, and the rest sorted by view, scan type, acquisition trajectory, and number of temporal frames (which would add a 1024*temporal frame to the excel formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04ea9024-b572-48e4-8d1d-529a6b92b315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 1024)\n",
      "(100, 1024)\n"
     ]
    }
   ],
   "source": [
    "#Seperating into x (pixel values) and y (Assigned Score), and further into train (n=400) and test (n=100) datasets\n",
    "y = df['Score'].values\n",
    "x = df.drop('Score',axis=1).values\n",
    "#print(y.shape)\n",
    "#print(x.shape)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2, random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91c532dc-d577-4cfd-be55-0bb59c978035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training SVM, K-nearest Neighbors, decision tree, and random forest to compare methods\n",
    "SVM_Quadrent_model = LinearSVC(dual='auto')\n",
    "SVM_Quadrent_model = SVM_Quadrent_model.fit(x_train,y_train)\n",
    "#I think SVM is a good model for this because, due to the nature of my substitute dataset, seperating hyperplanes in a grid would work well\n",
    "KNN_Quadrent_model = KNeighborsClassifier()\n",
    "KNN_Quadrent_model = KNN_Quadrent_model.fit(x_train,y_train)\n",
    "#KNN allows for classification based on similar datasets, which works well, and even better the further away from quadrant boundaries\n",
    "DT_Quadrent_model = DecisionTreeClassifier()\n",
    "DT_Quadrent_model = DT_Quadrent_model.fit(x_train,y_train)\n",
    "#I selected decision trees because only 20 of the 1024 pixels can appear in multiple classifications\n",
    "RF_Quadrent_model = RandomForestClassifier()\n",
    "RF_Quadrent_model = RF_Quadrent_model.fit(x_train,y_train)\n",
    "#Random Forest would be a good model because Decision Trees had worse test accuracy than SVN and KNN, while RF decorrolates the trees to not be too dependent on an early split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4919c8d4-d6a2-41a7-a651-76093b5adaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Train Accuracy = 1.0\n",
      "KNN Train Accuracy = 0.9975\n",
      "DT Train Accuracy = 1.0\n",
      "RF Train Accuracy = 1.0\n",
      "SVM Test Accuracy = 0.97\n",
      "KNN Test Accuracy = 0.98\n",
      "DT Test Accuracy = 0.9\n",
      "RF Test Accuracy = 0.98\n"
     ]
    }
   ],
   "source": [
    "#Testing and reporting relevant factors\n",
    "SVM_Train_Accuracy = SVM_Quadrent_model.score(x_train,y_train)\n",
    "KNN_Train_Accuracy = KNN_Quadrent_model.score(x_train,y_train)\n",
    "DT_Train_Accuracy = DT_Quadrent_model.score(x_train,y_train)\n",
    "RF_Train_Accuracy = RF_Quadrent_model.score(x_train,y_train)\n",
    "print('SVM Train Accuracy = ' + str(SVM_Train_Accuracy))\n",
    "print('KNN Train Accuracy = ' + str(KNN_Train_Accuracy))\n",
    "print('DT Train Accuracy = ' + str(DT_Train_Accuracy))\n",
    "print('RF Train Accuracy = ' + str(RF_Train_Accuracy))\n",
    "SVM_Test_Accuracy = SVM_Quadrent_model.score(x_test,y_test)\n",
    "KNN_Test_Accuracy = KNN_Quadrent_model.score(x_test,y_test)\n",
    "DT_Test_Accuracy = DT_Quadrent_model.score(x_test,y_test)\n",
    "RF_Test_Accuracy = RF_Quadrent_model.score(x_test,y_test)\n",
    "print('SVM Test Accuracy = ' + str(SVM_Test_Accuracy))\n",
    "print('KNN Test Accuracy = ' + str(KNN_Test_Accuracy))\n",
    "print('DT Test Accuracy = ' + str(DT_Test_Accuracy))\n",
    "print('RF Test Accuracy = ' + str(RF_Test_Accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242f2742-8338-465a-8e0e-3ae25a859755",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Results & Discussion:\n",
    "#Training Data accuracy was very high for all of the methods. \n",
    "#However, DT had consistently ~10% lower test accuracy than SVM and KNN (Multiple trainings resulted in slightly different accuracies)\n",
    "#I implemented RF to attempt to improve upon DT's test accuracy, and it was more in line with SVM and KNN\n",
    "#Overall, SVM, KNN, and RF performed well, and DT was good but not to the levels of the other 3\n",
    "#Since there is perfect delineation in the substitute dataset, there are very high accuracy scores\n",
    "#The clincal dataset is much more complex and will likely not produce this kind of accuracy\n",
    "#With this knowledge, I will focus on SVM, KNN, and RF models to use on my clinical dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
